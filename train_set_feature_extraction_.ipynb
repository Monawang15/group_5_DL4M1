{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import utils as u\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import os\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "VHuErY42vErA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLeUQEphtpZX"
      },
      "outputs": [],
      "source": [
        "test_file_paths = ['your_directory/data/CtrSVDD_0001_T_0006771.flac',\n",
        "                   'your_directory/data/CtrSVDD_0001_T_0006772.flac']  # Add your actual paths\n",
        "test_features, test_sr = u.load_and_extract_features(test_file_paths, feature_type='lfcc')\n",
        "\n",
        "print(\"Shape of extracted features:\", test_features.shape)\n",
        "print(\"Sample rate used:\", test_sr)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_file(file_path):\n",
        "    features, _ = u.load_and_extract_features([file_path], feature_type='lfcc')\n",
        "    return features"
      ],
      "metadata": {
        "id": "ZAxiOuGWuOcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_directory = '/Users/mona/Documents/GitHub/group_5_DL4M1/new_data/japanese_full_traning_dataset' #path to the directory containing the train set audio files\n",
        "\n",
        "#refer to ChatGPT\n",
        "audio_files = [os.path.join(dataset_directory, f) for f in os.listdir(dataset_directory) if f.endswith('.flac') and os.path.isfile(os.path.join(dataset_directory, f))]\n",
        "\n",
        "all_features = []\n",
        "for file_path in audio_files:\n",
        "    feature = process_file(file_path)\n",
        "    if feature is not None:\n",
        "        all_features.append(feature)\n",
        "\n",
        "# Optionally filter out None values and check shapes\n",
        "valid_features = []\n",
        "shapes = set()\n",
        "for feature in all_features:\n",
        "    valid_features.append(feature)\n",
        "    shapes.add(feature.shape)\n",
        "\n",
        "print(\"Unique feature shapes:\", shapes)"
      ],
      "metadata": {
        "id": "RfHoemsPuW-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine the maximum length from the shapes printed\n",
        "max_length = 0\n",
        "for shape in shapes:\n",
        "    length = shape[1]\n",
        "    if length > max_length:\n",
        "\n",
        "        max_length = length\\\n",
        "\n",
        "# Pad all features to the maximum length\n",
        "uniform_features = u.pad_features(all_features, max_length)\n",
        "\n",
        "# Convert list of arrays into a single numpy array for storage\n",
        "uniform_features_array = np.array(uniform_features)"
      ],
      "metadata": {
        "id": "g1u9opIPukf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an HDF5 file\n",
        "with h5py.File('your_directory/jap_LFCC_features_train.h5', 'w') as h5f:\n",
        "    # Create a dataset in the file\n",
        "    h5f.create_dataset('jap_LFCC_dataset_train', data=np.array(uniform_features_array))"
      ],
      "metadata": {
        "id": "NKqUssHQur9l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}